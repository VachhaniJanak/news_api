{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:24:28.696722Z","iopub.status.busy":"2024-09-16T06:24:28.696203Z","iopub.status.idle":"2024-09-16T06:24:45.154154Z","shell.execute_reply":"2024-09-16T06:24:45.153029Z","shell.execute_reply.started":"2024-09-16T06:24:28.696685Z"},"trusted":true},"outputs":[],"source":["!pip install rouge-score"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:24:45.156522Z","iopub.status.busy":"2024-09-16T06:24:45.156199Z","iopub.status.idle":"2024-09-16T06:25:04.758508Z","shell.execute_reply":"2024-09-16T06:25:04.757649Z","shell.execute_reply.started":"2024-09-16T06:24:45.156488Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset, load_metric\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n","import numpy as np\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:25:04.760138Z","iopub.status.busy":"2024-09-16T06:25:04.759559Z","iopub.status.idle":"2024-09-16T06:25:41.035216Z","shell.execute_reply":"2024-09-16T06:25:41.034417Z","shell.execute_reply.started":"2024-09-16T06:25:04.760104Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"multi_news\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:25:41.038337Z","iopub.status.busy":"2024-09-16T06:25:41.037852Z","iopub.status.idle":"2024-09-16T06:25:41.045323Z","shell.execute_reply":"2024-09-16T06:25:41.044437Z","shell.execute_reply.started":"2024-09-16T06:25:41.038287Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['document', 'summary'],\n","        num_rows: 44972\n","    })\n","    validation: Dataset({\n","        features: ['document', 'summary'],\n","        num_rows: 5622\n","    })\n","    test: Dataset({\n","        features: ['document', 'summary'],\n","        num_rows: 5622\n","    })\n","})"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:25:41.046541Z","iopub.status.busy":"2024-09-16T06:25:41.046283Z","iopub.status.idle":"2024-09-16T06:25:41.058925Z","shell.execute_reply":"2024-09-16T06:25:41.058083Z","shell.execute_reply.started":"2024-09-16T06:25:41.046512Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'document': Value(dtype='string', id=None),\n"," 'summary': Value(dtype='string', id=None)}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["dataset['train'].features"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:25:41.060508Z","iopub.status.busy":"2024-09-16T06:25:41.060150Z","iopub.status.idle":"2024-09-16T06:25:42.135258Z","shell.execute_reply":"2024-09-16T06:25:42.134312Z","shell.execute_reply.started":"2024-09-16T06:25:41.060467Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["National Archives \n"," \n"," Yes, it’s that time again, folks. It’s the first Friday of the month, when for one ever-so-brief moment the interests of Wall Street, Washington and Main Street are all aligned on one thing: Jobs. \n"," \n"," A fresh update on the U.S. employment situation for January hits the wires at 8:30 a.m. New York time offering one of the most important snapshots on how the economy fared during the previous month. Expectations are for 203,000 new jobs to be created, according to economists polled by Dow Jones Newswires, compared to 227,000 jobs added in February. The unemployment rate is expected to hold steady at 8.3%. \n"," \n"," Here at MarketBeat HQ, we’ll be offering color commentary before and after the data crosses the wires. Feel free to weigh-in yourself, via the comments section. And while you’re here, why don’t you sign up to follow us on Twitter. \n"," \n"," Enjoy the show. ||||| Employers pulled back sharply on hiring last month, a reminder that the U.S. economy may not be growing fast enough to sustain robust job growth. The unemployment rate dipped, but mostly because more Americans stopped looking for work. \n"," \n"," The Labor Department says the economy added 120,000 jobs in March, down from more than 200,000 in each of the previous three months. \n"," \n"," The unemployment rate fell to 8.2 percent, the lowest since January 2009. The rate dropped because fewer people searched for jobs. The official unemployment tally only includes those seeking work. \n"," \n"," The economy has added 858,000 jobs since December _ the best four months of hiring in two years. But Federal Reserve Chairman Ben Bernanke has cautioned that the current hiring pace is unlikely to continue without more consumer spending.\n"]}],"source":["print(dataset['train']['document'][0])"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:25:42.136689Z","iopub.status.busy":"2024-09-16T06:25:42.136358Z","iopub.status.idle":"2024-09-16T06:25:42.296609Z","shell.execute_reply":"2024-09-16T06:25:42.295759Z","shell.execute_reply.started":"2024-09-16T06:25:42.136655Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["– The unemployment rate dropped to 8.2% last month, but the economy only added 120,000 jobs, when 203,000 new jobs had been predicted, according to today's jobs report. Reaction on the Wall Street Journal's MarketBeat Blog was swift: \"Woah!!! Bad number.\" The unemployment rate, however, is better news; it had been expected to hold steady at 8.3%. But the AP notes that the dip is mostly due to more Americans giving up on seeking employment.\n"]}],"source":["print(dataset['train']['summary'][0]) "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:25:42.298754Z","iopub.status.busy":"2024-09-16T06:25:42.297943Z","iopub.status.idle":"2024-09-16T06:25:42.307611Z","shell.execute_reply":"2024-09-16T06:25:42.306716Z","shell.execute_reply.started":"2024-09-16T06:25:42.298718Z"},"trusted":true},"outputs":[],"source":["# Taking the subset of the dataset for the finetuning purpose\n","train_subset = dataset[\"train\"]\n","validation_subset = dataset[\"validation\"]\n","test_subset = dataset[\"test\"]"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:25:42.310539Z","iopub.status.busy":"2024-09-16T06:25:42.309855Z","iopub.status.idle":"2024-09-16T06:25:43.485361Z","shell.execute_reply":"2024-09-16T06:25:43.484519Z","shell.execute_reply.started":"2024-09-16T06:25:42.310505Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]}],"source":["checkpoint = 't5-small'\n","tokenizer = T5Tokenizer.from_pretrained(checkpoint)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:25:43.488497Z","iopub.status.busy":"2024-09-16T06:25:43.488157Z","iopub.status.idle":"2024-09-16T06:25:43.494554Z","shell.execute_reply":"2024-09-16T06:25:43.493459Z","shell.execute_reply.started":"2024-09-16T06:25:43.488464Z"},"trusted":true},"outputs":[],"source":["def preprocess_function(examples):\n","    inputs = [\"summarize: \" + doc for doc in examples[\"document\"]]\n","    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"summary\"], max_length=150, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:25:43.496089Z","iopub.status.busy":"2024-09-16T06:25:43.495741Z","iopub.status.idle":"2024-09-16T06:41:26.120923Z","shell.execute_reply":"2024-09-16T06:41:26.119997Z","shell.execute_reply.started":"2024-09-16T06:25:43.496056Z"},"trusted":true},"outputs":[],"source":["# Tokenize datasets\n","tokenized_train = train_subset.map(preprocess_function, batched=True)\n","tokenized_validation = validation_subset.map(preprocess_function, batched=True)\n","tokenized_test = test_subset.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:59:02.219091Z","iopub.status.busy":"2024-09-16T06:59:02.218229Z","iopub.status.idle":"2024-09-16T06:59:02.224279Z","shell.execute_reply":"2024-09-16T06:59:02.223227Z","shell.execute_reply.started":"2024-09-16T06:59:02.219038Z"},"trusted":true},"outputs":[],"source":["# Data collator\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:59:13.628560Z","iopub.status.busy":"2024-09-16T06:59:13.628162Z","iopub.status.idle":"2024-09-16T06:59:13.792204Z","shell.execute_reply":"2024-09-16T06:59:13.791316Z","shell.execute_reply.started":"2024-09-16T06:59:13.628523Z"},"trusted":true},"outputs":[],"source":["# Define compute_metrics function\n","rouge = load_metric(\"rouge\")\n","\n","def compute_metrics(pred):\n","    labels_ids = pred.label_ids\n","    pred_ids = pred.predictions\n","\n","    # Decode the predictions and labels\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n","    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n","\n","    # Compute ROUGE scores\n","    rouge_output = rouge.compute(predictions=pred_str, references=label_str, use_stemmer=True)\n","\n","    # Aggregate the ROUGE scores\n","    result = {key: value.mid.fmeasure * 100 for key, value in rouge_output.items()}\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in pred_ids]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","\n","    return result"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:59:14.648348Z","iopub.status.busy":"2024-09-16T06:59:14.647976Z","iopub.status.idle":"2024-09-16T06:59:14.739893Z","shell.execute_reply":"2024-09-16T06:59:14.738802Z","shell.execute_reply.started":"2024-09-16T06:59:14.648310Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["# Seq2Seq training arguments\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./results\",             # Directory to save model checkpoints and logs\n","    evaluation_strategy=\"epoch\",        # Evaluate the model at the end of each epoch\n","    learning_rate=2e-5,                 # Learning rate for the optimizer\n","    per_device_train_batch_size=16,     # Batch size for training\n","    per_device_eval_batch_size=16,      # Batch size for evaluation\n","    weight_decay=0.01,                  # Weight decay for regularization\n","    save_total_limit=3,                 # Limit the total number of checkpoints saved\n","    num_train_epochs=5,                 # Number of training epochs\n","    predict_with_generate=True,         # Use generation mode for prediction\n","    generation_max_length=150,          # Maximum length for generated sequences\n","    generation_num_beams=4,             # Number of beams for beam search during generation\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:59:17.688546Z","iopub.status.busy":"2024-09-16T06:59:17.688176Z","iopub.status.idle":"2024-09-16T06:59:20.182773Z","shell.execute_reply":"2024-09-16T06:59:20.182008Z","shell.execute_reply.started":"2024-09-16T06:59:17.688510Z"},"trusted":true},"outputs":[],"source":["## Seq2SeqTrainer\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,                       # The model to be trained\n","    args=training_args,                # Training arguments defined with Seq2SeqTrainingArguments\n","    train_dataset=tokenized_train,     # The training dataset\n","    eval_dataset=tokenized_validation, # The evaluation dataset\n","    data_collator=data_collator,       # The data collator for processing data batches\n","    tokenizer=tokenizer,               # The tokenizer used for preprocessing\n","    compute_metrics=compute_metrics,   # The function to compute evaluation metrics\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T17:14:36.505551Z","iopub.status.busy":"2024-09-14T17:14:36.504598Z","iopub.status.idle":"2024-09-14T18:08:44.031707Z","shell.execute_reply":"2024-09-14T18:08:44.030364Z","shell.execute_reply.started":"2024-09-14T17:14:36.505507Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2811' max='2811' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2811/2811 54:05, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.092000</td>\n","      <td>2.878141</td>\n","      <td>37.950024</td>\n","      <td>12.701885</td>\n","      <td>21.891300</td>\n","      <td>21.906595</td>\n","      <td>144.865884</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Train the model\n","trainer.train()\n","save_directory = './saved_model'\n","model.save_pretrained(save_directory)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:59:56.748737Z","iopub.status.busy":"2024-09-16T06:59:56.748360Z","iopub.status.idle":"2024-09-16T08:27:16.857347Z","shell.execute_reply":"2024-09-16T08:27:16.855379Z","shell.execute_reply.started":"2024-09-16T06:59:56.748700Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='704' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [352/352 1:18:18]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.18.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240916_075152-ddkd0ql3</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/vachhanijanak-10/huggingface/runs/ddkd0ql3' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/vachhanijanak-10/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/vachhanijanak-10/huggingface' target=\"_blank\">https://wandb.ai/vachhanijanak-10/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/vachhanijanak-10/huggingface/runs/ddkd0ql3' target=\"_blank\">https://wandb.ai/vachhanijanak-10/huggingface/runs/ddkd0ql3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.875044822692871, 'eval_model_preparation_time': 0.0053, 'eval_rouge1': 38.06026813699936, 'eval_rouge2': 12.679145428250266, 'eval_rougeL': 21.8045894617448, 'eval_rougeLsum': 21.80490631855089, 'eval_gen_len': 143.9530416221985, 'eval_runtime': 2107.9188, 'eval_samples_per_second': 2.667, 'eval_steps_per_second': 0.167}\n"]}],"source":["# Evaluate the model on validation set\n","trainer.evaluate()\n","\n","# Evaluate the model on test set\n","test_results = trainer.evaluate(eval_dataset=tokenized_test)\n","\n","print(test_results)"]},{"cell_type":"markdown","metadata":{},"source":["### Test"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Load Model\n","model = T5ForConditionalGeneration.from_pretrained('model/')"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["example_text = \"\"\"NEW YORK (Reuters) -More stocks are participating in the S&P 500’s latest march to record highs, easing concerns over a rally that has been concentrated in a handful of giant technology names for much of 2024.\n","\n","The S&P 500 gained 5.5% in the third quarter. This time, however, optimism that the Federal Reserve’s rate cuts will boost U.S. growth is pushing investors into shares of regional banks, industrial companies and other beneficiaries of a strong economy and lower rates, in addition to the tech-focused stocks that have already seen massive gains this year.\n","\n","More than 60% of S&P 500 components outperformed the index this quarter, compared to around 25% in the first half of the year. At the same time, the equal-weight version of the S&P 500 -- a proxy for the average index stock -- gained 9% in the quarter, outperforming the S&P 500, which is more influenced by the heavily weighted shares of megacaps such as Nvidia (NASDAQ:NVDA) and Apple (NASDAQ:AAPL).\n","\n","The broadening rally is an encouraging sign for stocks, investors said, following concerns that the market could be vulnerable to a reversal if the cluster of tech names propping it up fell out of favor. The “soft-landing” narrative of resilient growth will be tested by employment data at the end of the week and the start of corporate earnings season in October. \n","\n","The second half of the year so far is \"almost a mirror image of what the first half was,\" said Kevin Gordon, senior investment strategist at Charles Schwab (NYSE:SCHW). \"Even if the megacaps aren't contributing as much, as long as the rest of the market is doing well... I think that's a healthy development.”\n","\n","The Fed kicked off its first rate cutting cycle in four years earlier this month with a 50-basis point reduction, a move Chairman Jerome Powell said was meant to safeguard a resilient economy. Traders are pricing in some chance of another jumbo-sized reduction when the central bank meets again in November and project about 190 basis points of cuts through the end of 2025, according to LSEG data. \n","\n","Various corners of the stock market are benefiting from expectations of lower rates and steady growth.\n","\n","The S&P 500’s industrial and financials sectors - seen by investors as among the most economically sensitive areas - rose 11% and 10%, respectively, in the third quarter.\n","\n","Falling rates are also a boon to shares of smaller companies, which disproportionately struggle with elevated borrowing costs. The small-cap focused Russell 2000 climbed about 9% in the quarter.\n","\n","The market’s bond proxies - stocks with strong dividends - are also attracting investors seeking dividend income as bond yields fall alongside interest rates. Two such sectors, utilities and consumer staples, rose over 18% and 8%, respectively, in the period.\n","\n","Mark Hackett, chief of investment research at Nationwide, said the broadening builds on a trend that appeared before the September 17-18 Fed meeting.\n","\n","\"We were going to have this greater participation, this leveling of performance among sectors, and then you had the Fed cut more aggressively and that's leading to... an acceleration of that trend,\" he said.\n","\n","'QUITE HEALTHY' \n","\n","In all, eight of the S&P 500's 11 sectors outperformed the index in the third quarter. By comparison, only technology and the communications sector, which includes Google parent Alphabet (NASDAQ:GOOGL) and Facebook owner Meta Platforms (NASDAQ:META), outperformed the broader index in the first half of the year.\n","\n","The S&P 500 is up more than 20% year-to-date, at record-high levels.\n","\n","Meanwhile, the overall influence of the megacaps has moderated. The combined weight in the S&P 500 of the \"Magnificent Seven\" -- Apple, Microsoft (NASDAQ:MSFT), Nvidia, Amazon (NASDAQ:AMZN), Alphabet, Meta and Tesla (NASDAQ:TSLA) -- has declined to 31% from 34% in mid-July, according to LSEG Datastream.\n","\n","\"I find it to be quite healthy that tech has kind of consolidated,\" said King Lip, chief strategist at BakerAvenue Wealth Management. \"We're not in a bear market for tech by any means. But you've definitely seen some evidence of rotation.\"\n","\n","Investors would likely need to see further proof of economic strength for the broadening trend to continue. Jobs data on Oct. 4 will be one test of the soft landing scenario, after the prior two employment reports were weaker than expected.\n","\n","Market participants will also want to see non-tech firms deliver strong earnings in the months ahead to justify their gains.\n","\n","Magnificent Seven companies are expected to increase earnings by about 20% in the third quarter, against a profit rise of 2.5% for the rest of the S&P 500, according to Tajinder Dhillon, senior research analyst at LSEG. That gap is expected to shrink in 2025, with the rest of the index expected to increase earnings by 14% for the full year against a 19% rise for the megacap group.\n","\n","In a soft landing scenario, the Magnificent Seven \"should not have to carry the profit rebound alone,\" Lisa Shalett, chief investment officer at Morgan Stanley Wealth Management, said in a recent report.\n","\n","\"We are in the 'show me' stage for the soft landing,\" Shalett said.    \n","\n","\"\"\""]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T06:59:24.823508Z","iopub.status.busy":"2024-09-16T06:59:24.823073Z","iopub.status.idle":"2024-09-16T06:59:27.617284Z","shell.execute_reply":"2024-09-16T06:59:27.616388Z","shell.execute_reply.started":"2024-09-16T06:59:24.823453Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Generated Summary:\n"," – More than 60% of S&P 500 components outperformed the index this quarter, compared to around 25% in the first half of the year. At the same time, the equal-weight version of the 500 -- a proxy for the average index stock -- gained 9% in the quarter, outperforming the index, which is more influenced by the heavily weighted shares of megacaps such as Nvidia (NASDAQ:NVDA) and Apple (NASDAQ:AAPL), according to LSEG. \"Even if the megacaps aren't contributing as much, as long as the rest of the market is doing well... I think that's a healthy development,\" says Mark Hackett, senior investment strategist at Nationwide,\n"]}],"source":["# Preprocess the input text\n","input_text = \"summarize: \" + example_text\n","inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=2048, truncation=True)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","inputs = inputs.to(device)\n","# Generate the summary\n","summary_ids = model.generate(inputs, max_length=1024, min_length=64, length_penalty=4, num_beams=16, no_repeat_ngram_size=4\n",", early_stopping=True)\n","\n","# Decode the generated summary\n","summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","# print(\"Original Text:\\n\", example_text)\n","print(\"\\nGenerated Summary:\\n\", summary)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"isSourceIdPinned":true,"modelId":120392,"modelInstanceId":96209,"sourceId":114581,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
